# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: Copyright contributors to the vLLM project
import asyncio
import json
import queue
import threading
from abc import abstractmethod

import zmq

from vllm.config import FaultToleranceConfig
from vllm.logger import init_logger
from vllm.utils.collection_utils import ThreadSafeDict
from vllm.utils.network_utils import (
    get_open_port,
    make_zmq_socket,
    recv_router_dealer_message,
)
from vllm.v1.engine.exceptions import FaultInfo
from vllm.v1.engine.utils import broadcast_instruction, wait_for_instruction_result
from vllm.v1.serial_utils import (
    deserialize_method_call,
    run_method,
    serialize_method_call,
)

logger = init_logger(__name__)
# Polling timeout in milliseconds for non-blocking message reception
POLL_TIMEOUT_MS = 100


class BaseSentinel:
    """
    Abstract and constrain the core functionalities of the Sentinel.

    Core functionalities covered:
    - Fault listening
    - Fault tolerance instruction reception
    - Fault tolerance instruction execution
    - Upstream and downstream communication

    This class serves as the base abstraction for all LLM-related Sentinel
    implementations, enforcing standardized fault tolerance behavior across
    the system.
    """

    def __init__(
        self,
        upstream_cmd_addr: str | None,
        downstream_cmd_addr: str | None,
        dealer_socket_identity: bytes | None,
        sentinel_tag: str | None,
        fault_tolerance_config: FaultToleranceConfig,
    ):
        self.sentinel_dead = False
        self.ctx = zmq.Context()
        self.sentinel_tag = sentinel_tag
        self.logger = self._make_logger()
        self.ft_config = fault_tolerance_config
        if upstream_cmd_addr is not None:
            assert dealer_socket_identity is not None
            self.upstream_cmd_socket = make_zmq_socket(
                self.ctx,
                upstream_cmd_addr,
                zmq.DEALER,
                bind=False,
                identity=dealer_socket_identity,
            )
        if downstream_cmd_addr is not None:
            self.downstream_cmd_socket = make_zmq_socket(
                ctx=self.ctx,
                path=downstream_cmd_addr,
                socket_type=zmq.ROUTER,
                bind=True,
            )

    def _make_logger(self):
        def log(msg, *args, level="info", **kwargs):
            """
            level: "info", "warning", "error", "debug"
            msg: log message
            """
            prefix = self.sentinel_name
            getattr(logger, level)(prefix + msg, *args, **kwargs)

        return log

    @property
    def sentinel_name(self) -> str:
        if self.sentinel_tag is None:
            return f"[{self.__class__.__name__}] "
        return f"[{self.__class__.__name__}_{self.sentinel_tag}] "

    @abstractmethod
    def run(self) -> None:
        """
        The run() method is launched as a separate thread when a Sentinel
        instance is created.

        This background thread typically runs persistently to ensure real-time
        detection of errors and timely reception of fault tolerance instructions
        from upstream sentinels
        .
        """
        raise NotImplementedError

    def receive_upstream_cmd(self) -> tuple[bool, str | None]:
        """
        This method polls the upstream command socket and attempts to receive
        a serialized command message.
        """
        try:
            has_msg, _, cmd_str = recv_router_dealer_message(
                self.upstream_cmd_socket,
                use_poller=True,
                poll_timeout=POLL_TIMEOUT_MS,
            )
        except zmq.ZMQError:
            self.logger(
                "Socket closed, terminating %s", self.sentinel_name, level="info"
            )
            return False, None
        return has_msg, cmd_str

    def _execute_cmd(self, cmd_str: str) -> tuple[bool, str, str | None]:
        """
        Execute a command represented by a JSON string on the current object.
        The command string is expected to be generated by `serialize_method_call`,
        containing the method name, a unique ID for the command, and method
        parameters.

        Args:
        cmd_str (str): JSON string representing a serialized method call.

        Returns:
            tuple[bool, str, str | None]:
            - success (bool): True if the method ran without error; False otherwise.
            - method_uuid (str): Unique ID of the command.
            - reason (str | None): Error message if execution failed.
        """
        method, method_uuid, method_params = deserialize_method_call(cmd_str)
        self.logger("Executing command: %s", method, level="info")
        try:
            success: bool = run_method(self, method, args=(), kwargs=method_params)
            self.logger("Command (%s) succeeded: %s", method, success, level="info")
            reason = None
        except Exception as e:
            self.logger(
                "Error executing method %s: %s, %s",
                method,
                type(e).__name__,
                e,
                level="error",
            )
            success = False
            reason = f"{type(e).__name__}: {e}"
        return success, method_uuid, reason

    @abstractmethod
    def pause(self, timeout: int = 1, **kwargs) -> bool:
        """
        Pause the vLLM instance to enter fault-tolerance mode.
        This method should be called when a fault is detected. It pauses the
        execution, allowing the system to wait for fault-tolerance instructions
        (e.g., retry, scale-down, or other control commands).
        """
        raise NotImplementedError

    @abstractmethod
    def retry(self, timeout: int = 1, **kwargs) -> bool:
        """
        Retry execution after a transient recoverable fault.
        """
        raise NotImplementedError

    def _send_execution_result(
        self, success: bool, method_uuid: str, reason: str | None
    ):
        """
        Send the result of executing a command back to the upstream.
        """
        assert hasattr(self, "upstream_cmd_socket"), "upstream_cmd_socket is required"
        msg = {
            "sentinel_tag": self.sentinel_tag,
            "success": success,
            "method_uuid": method_uuid,
        }
        if not success and reason is not None:
            msg["reason"] = reason
        msg_bytes = json.dumps(msg).encode("utf-8")
        self.upstream_cmd_socket.send_multipart([b"", msg_bytes])

    def _broadcast_command_to_downstream(
        self,
        method_name: str,
        target_downstream_sentinels: set[bytes],
        timeout: int = 5,
        **kwargs,
    ):
        """
        Broadcast a command to downstream sentinels and collect responses.
        """
        kwargs["timeout"] = timeout
        method_uuid = broadcast_instruction(
            self.downstream_cmd_socket,
            target_downstream_sentinels,
            method_name,
            **kwargs,
        )

        responses = wait_for_instruction_result(
            self.downstream_cmd_socket,
            target_downstream_sentinels,
            method_name,
            timeout,
            method_uuid,
        )

        # check the execution results
        all_success = True
        for sentinel_identity in target_downstream_sentinels:
            response = responses.get(sentinel_identity)
            if response is None:
                self.logger(
                    'Downstream sentinels timed out on "%s".',
                    method_name,
                    level="error",
                )
                all_success = False
                break
            elif not response.get("success", False):
                self.logger(
                    'Downstream sentinels failed to execute command "%s" (reason: %s)',
                    method_name,
                    response.get("reason", "unknown"),
                    level="error",
                )
                all_success = False
                break

        return all_success, responses

    def shutdown(self):
        if (
            hasattr(self, "upstream_cmd_socket")
            and self.upstream_cmd_socket is not None
        ):
            self.upstream_cmd_socket.close()
        if (
            hasattr(self, "downstream_cmd_socket")
            and self.downstream_cmd_socket is not None
        ):
            self.downstream_cmd_socket.close()
        if self.ctx is not None:
            self.ctx.term()
        self.sentinel_dead = True


class ClientSentinel(BaseSentinel):
    def __init__(
        self,
        fault_receiver_addr: str,
        cmd_addr: str,
        engine_registry: dict[int, bytes],
        engine_exception_q: queue.Queue[FaultInfo],
        fault_pub_addr: str,
        engine_status_dict: ThreadSafeDict[int, str],
        fault_tolerance_config: FaultToleranceConfig,
    ):
        super().__init__(
            upstream_cmd_addr=None,
            downstream_cmd_addr=cmd_addr,
            dealer_socket_identity=None,
            sentinel_tag=None,
            fault_tolerance_config=fault_tolerance_config,
        )
        self.is_faulted = threading.Event()
        self.engine_running = threading.Event()
        self.engine_running.set()
        self.engine_registry = engine_registry
        self.engine_exception_q: queue.Queue[FaultInfo] = engine_exception_q
        self.engine_status_dict: ThreadSafeDict[int, str] = engine_status_dict
        self.engine_identity_to_index: dict[bytes, int] = {
            identity: i for i, identity in self.engine_registry.items()
        }

        self.fault_receiver_socket = make_zmq_socket(
            ctx=self.ctx,
            path=fault_receiver_addr,
            socket_type=zmq.ROUTER,
            bind=True,
        )
        self.fault_pub_socket = make_zmq_socket(
            ctx=self.ctx, path=fault_pub_addr, socket_type=zmq.PUB, bind=True
        )

        # All fault-tolerance related instructions (e.g. pause / retry) MUST be
        # executed strictly sequentially.
        # All instructions, regardless of which thread they originate from, are
        # enqueued into this queue.
        self._task_queue: asyncio.Queue = asyncio.Queue()
        self._loop = asyncio.get_event_loop()
        # The dispatcher runs in the event loop and dequeues tasks one by one,
        # executing them in FIFO order
        self._dispatcher_task = self._loop.create_task(self._dispatcher())

        threading.Thread(
            target=self.run, daemon=True, name="ClientSentinelMonitorThread"
        ).start()

    def run(self) -> None:
        """
        Block the current execution flow and listen for fault information:
        1. Block the thread on the error message queue
        2. Unblock only when fault is received
        3. Execute the pause command immediately upon detecting an fault message
        """
        while not self.sentinel_dead:
            try:
                self.listen_and_publish_fault_status()
                # Pause healthy engines on fault.
                # Pause can be invoked again during fault-tolerance handling,
                # so it's unnecessary to track whether all engines are currently
                # paused.
                if self.engine_running.is_set():
                    self._submit_task(
                        "pause", self.ft_config.gloo_comm_timeout, soft_pause=False
                    )
            except zmq.ZMQError:
                # Socket is closed.
                break

    def _submit_task(self, instruction: str, timeout: int, **kwargs) -> None:
        """
        thread-safe fire-and-forget submission of a fault handling task.
        This method can be called from **any thread**
        """

        def _enqueue():
            fut = self._loop.create_future()
            self._task_queue.put_nowait((instruction, timeout, kwargs, fut))

        self._loop.call_soon_threadsafe(_enqueue)

    async def _dispatcher(self):
        while True:
            # each elements in the queue contains:
            # (instruction, timeout, kwargs, future)
            instruction, timeout, kwargs, fut = await self._task_queue.get()
            try:
                kwargs["timeout"] = timeout
                cmd_str = serialize_method_call(instruction, None, **kwargs)
                success, _, _ = self._execute_cmd(cmd_str)
                if fut:
                    fut.set_result(success)
            except Exception as e:
                if fut:
                    fut.set_exception(e)

    def retry(self, timeout: int = 1, **kwargs) -> bool:
        if "Dead" in self.engine_status_dict.values():
            self.logger(
                "Engine core is dead; retry won't work.",
                level="warning",
            )
            return False

        target_engines = set(self.engine_identity_to_index.keys())
        new_stateless_dp_group_port = get_open_port()
        success, _ = self._broadcast_command_to_downstream(
            "retry",
            target_engines,
            new_stateless_dp_group_port=new_stateless_dp_group_port,
            timeout=timeout,
        )

        for engine_index, _ in self.engine_status_dict.items():
            self.engine_status_dict[engine_index] = "Healthy"
        while not self.engine_exception_q.empty():
            try:
                self.engine_exception_q.get_nowait()
            except queue.Empty:
                break

        if success:
            self.is_faulted.clear()
            self.engine_running.set()
        return success

    def pause(self, timeout: int = 1, **kwargs) -> bool:
        self.logger(
            "Pause operation is best-effort only. Due to the complexity of "
            "collective communications (e.g., timing dependencies and "
            "synchronization barriers), pausing may not always succeed. If "
            "the process remains unresponsive or collective operations "
            "cannot be interrupted, consider shutting down and restarting "
            "the instance.",
            level="warning",
        )
        exclude_engine_index = kwargs.get("exclude_engine_index")
        soft_pause = kwargs.get("soft_pause", False)
        self.engine_running.clear()
        alive_engines = {
            identity
            for identity, index in self.engine_identity_to_index.items()
            if self.engine_status_dict.get(index) != "Dead"
            and (exclude_engine_index is None or index not in exclude_engine_index)
        }
        success, _ = self._broadcast_command_to_downstream(
            "pause",
            alive_engines,
            timeout=timeout,
            soft_pause=soft_pause,
        )
        return success

    async def handle_fault(self, instruction: str, timeout: int, **kwargs) -> bool:
        """
        Executes fault tolerance methods based on the fault tolerance instructions
         received from the api_server.
        """
        fut = self._loop.create_future()
        await self._task_queue.put((instruction, timeout, kwargs, fut))
        success = await fut
        return success

    def listen_and_publish_fault_status(self):
        try:
            _, sender_identity, message = recv_router_dealer_message(
                self.fault_receiver_socket
            )
            assert message is not None, (
                "message should not be None at fault tolerance scenario"
            )

            fault_info = FaultInfo.from_json(message)
            self.engine_exception_q.put_nowait(fault_info)
            engine_status = "Dead" if "dead" in fault_info.type else "Unhealthy"
            self.engine_status_dict[int(fault_info.engine_id)] = engine_status
            self.fault_pub_socket.send_string(
                f"vllm_fault|{json.dumps(self.engine_status_dict.to_dict())}"
            )
            self.is_faulted.set()
        except zmq.ZMQError:
            # Socket was closed during polling, exit loop.
            self.logger("Fault receiver socket closed, stopping thread.", level="info")
            raise

    def shutdown(self):
        self.fault_receiver_socket.close()
        self.fault_pub_socket.close()
        super().shutdown()
        self.logger("ClientSentinel is closed.", level="info")
